\documentclass[12pt]{article}

\usepackage[letterpaper, hmargin=0.75in, vmargin=0.75in]{geometry}
\usepackage{float}

\pagestyle{empty}

\title{ECE 459: Programming for Performance\\Assignment 2}
\author{Your Name}
\date{February 24, 2015}

\begin{document}

\maketitle

{\bf I verify I ran all benchmarks on a REPLACEWITHCPU with at least 4 physical cores and
{\tt OMP\_NUM\_THREADS} set to 4 (I double checked with
{\tt echo \$OMP\_NUM\_THREADS})}

\section*{Automatic Parallelization (40 marks)}

\begin{table}[H]
  \centering
  \begin{tabular}{lr}
    & {\bf Time (s)} \\
    \hline
    Run 1 & 6.382 \\
    Run 2 & 6.330 \\
    Run 3 & 6.087 \\
    \hline
    Average & 6.266 \\
  \end{tabular}
  \caption{Benchmark results for raytrace unoptimized sequential execution}
  \label{tbl-raytrace-unopt-sequential}
\end{table}

\begin{table}[H]
  \centering
  \begin{tabular}{lr}
    & {\bf Time (s)} \\
    \hline
    Run 1 & 3.001 \\
    Run 2 & 3.201 \\
    Run 3 & 2.905 \\
    \hline
    Average & 3.035 \\
  \end{tabular}
  \caption{Benchmark results for raytrace optimized sequential execution}
  \label{tbl-raytrace-opt-sequential}
\end{table}

\begin{table}[H]
  \centering
  \begin{tabular}{lr}
    & {\bf Time (s)} \\
    \hline
    Run 1 & 2.808 \\
    Run 2 & 2.825 \\
    Run 3 & 2.797 \\
    \hline
    Average & 2.810 \\
  \end{tabular}
  \caption{Benchmark results for raytrace with automatic parallelization}
  \label{tbl-raytrace-automatic}
\end{table}


The speedup seen in {\bf Table~\ref{tbl-raytrace-unopt-sequential}} compared with {\bf Table~\ref{tbl-raytrace-opt-sequential}} is due to the fact that the compiler was instructed to tune the executable for maximum runtime performance, as per the docs found in {\tt https://docs.oracle.com/cd/E37069\_01/html/E37074/bjapp.html}. The speed up due to the compiler is approximately 2.065.

To allow for the automatic parallelization of {\tt raytrace\_auto.c}, the {\tt vectorAdd}, {\tt vectorScale}, {\tt vectorSub}, and {\tt vectorDot} functions had to be implemented using macros. This is because producton compilers will usually avoid parallelizing loops with function calls as they can have arbitrary side effects. In this case, there isn't any side effect as it is a simple function that takes inputs, does some calculation, and gives a result, but the compiler does not look into the specifics of the function.

The changes made are correct because they are functionally equivalent to the original implementation with dedicated functions. They only difference now is that a function call isn't required to do the calculation. However, although this change is functionally correct, it is bad for maintainability. Macros do not have type-safety. They also make the readability of the coder harder. Finally, they substitutions, which can cause undesired reults. For example: \\
{\tt \#define max(a,b) ((a)>(b)?:(a):(b))} \\
followed by \\
{\tt std:max(a,b);} \\
may result in \\
{\tt std::((a)>(b)?:(a):(b));} \\
by some compilers. \\

The speed up sin in {\bf Table~\ref{tbl-raytrace-automatic}} compared with {\bf Table~\ref{tbl-raytrace-opt-sequential}} is approximately 1.080.

\section*{Manual Parallelization with OpenMP (30 marks)}

\begin{table}[H]
  \centering
  \begin{tabular}{lr}
    & {\bf Time (s)} \\
    \hline
    Run 1 & 0 \\
    Run 2 & 0 \\
    Run 3 & 0 \\
    Run 4 & 0 \\
    Run 5 & 0 \\
    Run 6 & 0 \\
    \hline
    Average & 0 \\
  \end{tabular}
  \caption{Benchmark results for zeta execution with manual OpenMP ({\tt i} = \zetaIterations{})}
  \label{tbl-zeta-openmp}
\end{table}

%% Explain why things got better.

\section*{Using OpenMP Tasks (30 marks)}

\begin{table}[H]
  \centering
  \begin{tabular}{lr}
    & {\bf Time (s)} \\
    \hline
    Run 1 & 14.933 \\
    Run 2 & 15.477 \\
    Run 3 & 16.293 \\
    Run 4 & 15.929 \\
    Run 5 & 16.780 \\
    Run 6 & 15.103 \\
    \hline
    Average & 15.753 \\
  \end{tabular}
  \caption{Benchmark results for N-Queens sequential execution ({\tt n} = 14)}
  \label{tbl-nqueens-sequential}
\end{table}

\begin{table}[H]
  \centering
  \begin{tabular}{lr}
    & {\bf Time (s)} \\
    \hline
    Run 1 & 8.473 \\
    Run 2 & 9.632 \\
    Run 3 & 8.629 \\
    Run 4 & 8.203 \\
    Run 5 & 8.155 \\
    Run 6 & 8.935 \\
    \hline
    Average & 8.671 \\
  \end{tabular}
  \caption{Benchmark results for N-Queens execution with OpenMP tasks ({\tt n} = 14)}
  \label{tbl-nqueens-tasks}
\end{table}

As seen in {\bf Table~\ref{tbl-nqueens-sequential}}, an average execution time of 15.753s was observed for the sequential execution. From {bf Table~\ref{tbl-nqueens-tasks}}, an average execution time of 8.671s was observed for the execution with OpenMP taks. This results in a speedup of approximately 1.82x.

The implementation using OpenMP improved performance because this implementation of the N-Queens problem has calculations that depend very little on eachother. Because of this, a thread can be spawned for each calculation. However, spawning OpenMP tasks has non-negligible overhead which adds up - as seen when the directive was applied without any cutoff.

The cutoff applied to this implementation was 4. The cutoff means that only the first levels in the recursion tree will have tasks spawned, the rest of the functions called because of the recursion will be executed sequentially. This saves the overhead that will increase exponentially if there was no cutoff.

There are \( n^n \) max function calls (it will be less because of the check with the {\tt safe} function to prune some branches, but for now assume upper bound. This means there could be up to \( n^n \) (worse than factorial) tasks generated without cutoff and up to \( n^{cutoff} \) (polynomial) tasks spawned with cutoff.

\end{document}
