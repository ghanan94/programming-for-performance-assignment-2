\documentclass[12pt]{article}

\usepackage[letterpaper, hmargin=0.75in, vmargin=0.75in]{geometry}
\usepackage{float}

\pagestyle{empty}

\title{ECE 459: Programming for Performance\\Assignment 2}
\author{Ghanan Gowripalan}
\date{\today}

\begin{document}

\maketitle

{\bf I verify I ran all benchmarks on a Intel(R) Core(TM) i7-2600K CPU @ 3.40GHz with at least 4 physical cores and
{\tt OMP\_NUM\_THREADS} set to 4 (I double checked with
{\tt echo \$OMP\_NUM\_THREADS})}

\section*{Automatic Parallelization (40 marks)}

\begin{table}[H]
  \centering
  \begin{tabular}{lr}
    & {\bf Time (s)} \\
    \hline
    Run 1 & 6.382 \\
    Run 2 & 6.330 \\
    Run 3 & 6.087 \\
    \hline
    Average & 6.266 \\
  \end{tabular}
  \caption{Benchmark results for raytrace unoptimized sequential execution}
  \label{tbl-raytrace-unopt-sequential}
\end{table}

\begin{table}[H]
  \centering
  \begin{tabular}{lr}
    & {\bf Time (s)} \\
    \hline
    Run 1 & 3.001 \\
    Run 2 & 3.201 \\
    Run 3 & 2.905 \\
    \hline
    Average & 3.035 \\
  \end{tabular}
  \caption{Benchmark results for raytrace optimized sequential execution}
  \label{tbl-raytrace-opt-sequential}
\end{table}

\begin{table}[H]
  \centering
  \begin{tabular}{lr}
    & {\bf Time (s)} \\
    \hline
    Run 1 & 2.808 \\
    Run 2 & 2.825 \\
    Run 3 & 2.797 \\
    \hline
    Average & 2.810 \\
  \end{tabular}
  \caption{Benchmark results for raytrace with automatic parallelization}
  \label{tbl-raytrace-automatic}
\end{table}


The speedup seen in {\bf Table~\ref{tbl-raytrace-unopt-sequential}} compared with {\bf Table~\ref{tbl-raytrace-opt-sequential}} is due to the fact that the compiler was instructed to tune the executable for maximum runtime performance, as per the docs found in {\tt https://docs.oracle.com/cd/E37069\_01/html/E37074/bjapp.html}. The speed up due to the compiler is approximately 2.065.

To allow for the automatic parallelization of {\tt raytrace\_auto.c}, the {\tt vectorAdd}, {\tt vectorScale}, {\tt vectorSub}, and {\tt vectorDot} functions had to be implemented using macros. This is because producton compilers will usually avoid parallelizing loops with function calls as they can have arbitrary side effects. In this case, there isn't any side effect as it is a simple function that takes inputs, does some calculation, and gives a result, but the compiler does not look into the specifics of the function.

The changes made are correct because they are functionally equivalent to the original implementation with dedicated functions. They only difference now is that a function call isn't required to do the calculation. However, although this change is functionally correct, it is bad for maintainability. Macros do not have type-safety. They also make the readability of the coder harder. Finally, they substitutions, which can cause undesired reults. For example: \\
{\tt \#define max(a,b) ((a)>(b)?:(a):(b))} \\
followed by \\
{\tt std:max(a,b);} \\
may result in \\
{\tt std::((a)>(b)?:(a):(b));} \\
by some compilers. \\

The speed up sin in {\bf Table~\ref{tbl-raytrace-automatic}} compared with {\bf Table~\ref{tbl-raytrace-opt-sequential}} is approximately 1.080.

\section*{Manual Parallelization with OpenMP (30 marks)}

\begin{table}[H]
  \centering
  \begin{tabular}{lr}
    & {\bf Time (s)} \\
    \hline
    Run 1 & 1.165 \\
    Run 2 & 1.179 \\
    Run 3 & 1.172 \\
    Run 4 & 1.150 \\
    Run 5 & 1.185 \\
    Run 6 & 1.008 \\
    \hline
    Average & 1.143 \\
  \end{tabular}
  \caption{Benchmark results for edge detector sequential execution}
  \label{tbl-canny-edge-sequential}
\end{table}

\begin{table}[H]
  \centering
  \begin{tabular}{lr}
    & {\bf Time (s)} \\
    \hline
    Run 1 & 0.786 \\
    Run 2 & 0.789 \\
    Run 3 & 0.811 \\
    Run 4 & 0.793 \\
    Run 5 & 0.816 \\
    Run 6 & 0.847 \\
    \hline
    Average & 0.807 \\
  \end{tabular}
  \caption{Benchmark results for edge detector execution with manual OpenMP}
  \label{tbl-canny-edge-openmp}
\end{table}

The sequential execution of the edge detector was observed to be approximately 1.143s on average as per {\bf Table~\ref{tbl-canny-edge-sequential}}. The execution with manual OpenMP of the edge detector was observed to be approximately 0.807s on average as per {\bf Table~\ref{tbl-canny-edge-openmp}}. This means there was a speedup of approximately 1.42x.

The speed up was made possible by parallelizing the various for-loops in the code that iterated over the rows and columns. There was approximately 4000 rows and 3000 columns being analyzed in each group of (nested) for loops, where some of the calculations involved the {\tt sqrt}, or {\tt pow} functions which take relatively longer than other calculations.

The parallelized version is implemented to be race free, because the loops that were parallelized only wrote to various elements in the array. However, no two seperate iterations write to the same element in the arrays so there is no dependancies between writes and/or reads.

The resulting file from the OpenMP implementation was compared with the sequential version and there was no difference. This test was done 10x. (This is not a conclusive test on its own because it could just be that the race condition didn't happen to occur in the 10 trials, but it is a good indication + the explaination above as to why there is no race conditions).

\section*{Using OpenMP Tasks (30 marks)}

\begin{table}[H]
  \centering
  \begin{tabular}{lr}
    & {\bf Time (s)} \\
    \hline
    Run 1 & 14.933 \\
    Run 2 & 15.477 \\
    Run 3 & 16.293 \\
    Run 4 & 15.929 \\
    Run 5 & 16.780 \\
    Run 6 & 15.103 \\
    \hline
    Average & 15.753 \\
  \end{tabular}
  \caption{Benchmark results for N-Queens sequential execution ({\tt n} = 14)}
  \label{tbl-nqueens-sequential}
\end{table}

\begin{table}[H]
  \centering
  \begin{tabular}{lr}
    & {\bf Time (s)} \\
    \hline
    Run 1 & 8.473 \\
    Run 2 & 9.632 \\
    Run 3 & 8.629 \\
    Run 4 & 8.203 \\
    Run 5 & 8.155 \\
    Run 6 & 8.935 \\
    \hline
    Average & 8.671 \\
  \end{tabular}
  \caption{Benchmark results for N-Queens execution with OpenMP tasks ({\tt n} = 14)}
  \label{tbl-nqueens-tasks}
\end{table}

As seen in {\bf Table~\ref{tbl-nqueens-sequential}}, an average execution time of 15.753s was observed for the sequential execution. From {bf Table~\ref{tbl-nqueens-tasks}}, an average execution time of 8.671s was observed for the execution with OpenMP taks. This results in a speedup of approximately 1.82x.

The implementation using OpenMP improved performance because this implementation of the N-Queens problem has calculations that depend very little on eachother. Because of this, a thread can be spawned for each calculation. However, spawning OpenMP tasks has non-negligible overhead which adds up - as seen when the directive was applied without any cutoff.

The cutoff applied to this implementation was 4. The cutoff means that only the first levels in the recursion tree will have tasks spawned, the rest of the functions called because of the recursion will be executed sequentially. This saves the overhead that will increase exponentially if there was no cutoff.

There are \( n^n \) max function calls (it will be less because of the check with the {\tt safe} function to prune some branches, but for now assume upper bound. This means there could be up to \( n^n \) (worse than factorial) tasks generated without cutoff and up to \( n^{cutoff} \) (polynomial) tasks spawned with cutoff.

\end{document}
